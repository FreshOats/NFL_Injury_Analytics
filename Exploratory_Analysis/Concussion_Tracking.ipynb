{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punt Play Analytics - Unsupervised Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Cleaning dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from InjuryCleaningFunctions import *\n",
    "from NGS_Sampler import ngs_sampler\n",
    "from Punt_Cleaner import Punt_Cleaner\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "random = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import (and Sample) the NGS data and return as a dataframe\n",
    "\n",
    "The ngs data contains over 60 million rows of data, which will ultimately need to be sampled to perform additional modeling. The NGS_Cleaner funcntion from NGS_Sampler already samples the data down to a specified percent. In this case, we are sampling 1%, returning a dataframe with 600,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngs = ngs_sampler(fraction=0.001, random=random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will import and merge the punt analytics tables except for the NGS data\n",
    "punt = Punt_Cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge perform an inner merge so that we have data for all columns and are not ignoring potentially important features in the unsupervised analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punt_ngs = pd.merge(punt, ngs, on='Game_Play_ID', how = \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the merged data, since it will be inevitable during the plots and processing that something is going to get overwritten, and it will be very painful to reprocess the merge with the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = punt_ngs.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 18:44:54) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a128abeef29120eb7bd22a6a2e883184ae9f9178564f0df9c7c7d3d676105f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
